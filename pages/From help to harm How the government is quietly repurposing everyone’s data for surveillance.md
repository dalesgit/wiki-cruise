---
created: 2025-04-23T08:22:05 (UTC -10:00)
tags: []
source: https://theconversation.com/from-help-to-harm-how-the-government-is-quietly-repurposing-everyones-data-for-surveillance-254690
author: Nicole M. Bennett
---

# From help to harm: How the government is quietly repurposing everyone’s data for surveillance

> ## Excerpt
> Under the guise of efficiency and fraud prevention, the federal government is breaking down data silos to collect and aggregate information on virtually everyone in the US.

---
A whistleblower at the National Labor Relations Board reported an unusual [spike in potentially sensitive data flowing out](https://www.npr.org/2025/04/15/nx-s1-5355896/doge-nlrb-elon-musk-spacex-security) of the agency’s network in early March 2025 when staffers from the Department of Government Efficiency, which goes by DOGE, were granted access to the agency’s databases. On April 7, the Department of Homeland Security [gained access](https://www.cnn.com/2025/04/08/politics/irs-dhs-sign-data-deal-undocumented-immigrants/index.html) to Internal Revenue Service tax data.

These seemingly unrelated events are examples of recent developments in the transformation of the structure and purpose of federal government data repositories. I am a researcher [who studies](https://scholar.google.com/citations?user=JnTFiOQAAAAJ&hl=en) the intersection of migration, data governance and digital technologies. I’m tracking how data that people provide to U.S. government agencies for public services such as tax filing, health care enrollment, unemployment assistance and education support is increasingly being redirected toward surveillance and law enforcement.

Originally collected to facilitate health care, eligibility for services and the administration of public services, this information is now shared across government agencies and with private companies, reshaping the infrastructure of public services into a mechanism of control. Once confined to separate bureaucracies, [data now flows freely through a network](https://www.dni.gov/files/ODNI/documents/assessments/ODNI-Declassified-Report-on-CAI-January2022.pdf) of interagency agreements, outsourcing contracts and commercial partnerships built up in recent decades.

These data-sharing arrangements often take place outside public scrutiny, driven by [national security justifications](https://www.repository.law.indiana.edu/cgi/viewcontent.cgi?referer=&httpsredir=1&article=1148&context=facpub), [fraud prevention initiatives](https://home.treasury.gov/news/press-releases/jy2650) and [digital modernization efforts](https://www.cdc.gov/media/releases/2024/p0411-CDC-data-modernization.html). The result is that the structure of government is quietly transforming into an integrated surveillance apparatus, capable of monitoring, predicting and flagging behavior at an unprecedented scale.

Executive orders signed by President Donald Trump aim to remove remaining institutional and legal barriers to completing this massive surveillance system.

## DOGE and the private sector

Central to this transformation is DOGE, which is tasked via an [executive order](https://www.whitehouse.gov/presidential-actions/2025/01/establishing-and-implementing-the-presidents-department-of-government-efficiency/) to “promote inter-operability between agency networks and systems, ensure data integrity, and facilitate responsible data collection and synchronization.” An additional [executive order](https://www.whitehouse.gov/presidential-actions/2025/03/stopping-waste-fraud-and-abuse-by-eliminating-information-silos/) calls for the federal government to eliminate its information silos.

By building interoperable systems, DOGE can enable real-time, cross-agency access to sensitive information and create a [centralized database on people within the U.S](https://www.wired.com/story/doge-collecting-immigrant-data-surveil-track/). These developments are framed as administrative streamlining but lay the groundwork for mass surveillance.

Key to this data repurposing are public-private partnerships. The DHS and other agencies have [turned to third-party contractors and data brokers](https://theconversation.com/us-agencies-buy-vast-quantities-of-personal-information-on-the-open-market-a-legal-scholar-explains-why-and-what-it-means-for-privacy-in-the-age-of-ai-207707) to bypass direct restrictions. These intermediaries also consolidate data from [social media, utility companies, supermarkets and many other sources](https://www.brennancenter.org/our-work/research-reports/closing-data-broker-loophole), enabling enforcement agencies to construct detailed digital profiles of people without explicit consent or judicial oversight.

Palantir, a private data firm and prominent federal contractor, supplies investigative platforms to agencies such as [Immigration and Customs Enforcement](https://www.404media.co/ice-just-paid-palantir-tens-of-millions-for-complete-target-analysis-of-known-populations/), the [Department of Defense](https://www.washingtonpost.com/business/2019/08/22/war-inside-palantir-data-mining-firms-ties-ice-under-attack-by-employees/), [the Centers for Disease Control and Prevention](https://fedscoop.com/cdc-again-expands-palantir-disease-contract-2022/) and the [Internal Revenue Service](https://www.wired.com/story/palantir-doge-irs-mega-api-data/). These platforms aggregate data from various sources – [driver’s license photos](https://www.fastcompany.com/3069264/congress-fbi-face-recognition-real-time-street-lineup), [social services](https://www.palantir.com/offerings/federal-health/), [financial information](https://www.palantir.com/offerings/financial-services/government/), [educational data](https://www.insidehighered.com/news/government/politics-elections/2025/02/08/doges-access-education-department-data-raises) – and present it in centralized dashboards designed for predictive policing and algorithmic profiling. These tools extend government reach in ways that challenge existing norms of privacy and consent.

## The role of AI

[Artificial intelligence](https://www.washingtonpost.com/nation/2025/02/06/elon-musk-doge-ai-department-education/) has further accelerated this shift.

Predictive algorithms now [scan vast amounts of data](https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/) to generate risk scores, detect anomalies and flag potential threats.

These systems [ingest data](https://community.lawschool.cornell.edu/wp-content/uploads/2025/03/Lin-note-final.pdf) from school enrollment records, housing applications, utility usage and even social media, all made available through [contracts with data brokers and tech companies](https://techpolicy.sanford.duke.edu/wp-content/uploads/sites/4/2021/08/Data-Brokers-and-Sensitive-Data-on-US-Individuals-Sherman-2021.pdf). Because these systems rely on machine learning, their inner workings are often proprietary, unexplainable and beyond meaningful public accountability.

<iframe data-src="https://www.youtube.com/embed/QN6ac0N9Izc?wmode=transparent&amp;start=0" frameborder="0" allowfullscreen="" width="100%" height="400"></iframe>

Data privacy researcher Justin Sherman explains the astonishing amount of information data brokers have about you.

Sometimes the results are inaccurate, generated by [AI hallucinations](https://mitsloanedtech.mit.edu/ai/basics/addressing-ai-hallucinations-and-bias/) – responses AI systems produce that sound convincing but are [incorrect, made up or irrelevant](https://theconversation.com/what-are-ai-hallucinations-why-ais-sometimes-make-things-up-242896). Minor data discrepancies can lead to major consequences: [job loss, denial of benefits and wrongful targeting](https://www.google.com/books/edition/Automating_Inequality/pn4pDwAAQBAJ?hl=en&gbpv=1&dq=inauthor:%22Virginia+Eubanks%22&printsec=frontcover) in law enforcement operations. Once flagged, individuals rarely have a clear pathway to contest the system’s conclusions.

## Digital profiling

Participation in civic life, applying for a loan, seeking disaster relief and requesting student aid now contribute to a person’s digital footprint. Government entities could later interpret that data in ways that allow them to deny access to assistance. Data collected under the banner of care could be mined for evidence to justify placing someone under surveillance. And with growing dependence on private contractors, the boundaries between public governance and corporate surveillance continue to erode.

[Artificial intelligence](https://bhm.scholasticahq.com/article/38021-misguided-artificial-intelligence-how-racial-bias-is-built-into-clinical-models), [facial recognition systems](https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212) and predictive profiling systems [lack oversight](https://research.tilburguniversity.edu/en/publications/predictive-profiling-and-its-legal-limits-effectiveness-gone-fore). They also [disproportionately affect](https://naacp.org/resources/artificial-intelligence-predictive-policing-issue-brief) low-income individuals, immigrants and [people of color](https://epic.org/issues/democracy-free-speech/privacy-and-racial-justice/), who are [more frequently flagged as risks](https://www.innovatingjustice.org/wp-content/uploads/2019/07/Beyond_The_Algorithm.pdf).

Initially built for benefits verification or crisis response, these data systems now feed into broader surveillance networks. The implications are profound. What began as a system targeting noncitizens and fraud suspects could easily be generalized to everyone in the country.

## Eyes on everyone

This is not merely a question of data privacy. It is a broader transformation in the logic of governance. Systems once designed for administration have become tools for tracking and predicting people’s behavior. In this new paradigm, oversight is sparse and accountability is minimal.

AI allows for the interpretation of behavioral patterns at scale without direct interrogation or verification. Inferences replace facts. Correlations replace testimony.

The risk extends to everyone. While these technologies are often first deployed at the [margins of society](https://www.uottawa.ca/en/news-all/consequences-experimenting-ai-emerging-technologies-migrant-communities-border) – against migrants, welfare recipients or those deemed “high risk” – there’s little to limit their scope. As the infrastructure expands, so does its reach into the lives of all citizens.

With every form submitted, interaction logged and device used, a digital profile deepens, often out of sight. The infrastructure for pervasive surveillance is in place. What remains uncertain is how far it will be allowed to go.
